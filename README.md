# Test task for Alter

Сервис реализован с помощью стека *PHP7/ApiPlatform/Symfony5/RoadRunner/PostgreSQL*. *ApiPlatform* - удобное и 
мощное решение для создания REST API и GraphQL сервисов, с поддержкой Swagger/OpenAPI "из коробки", основанное
на фреймворке *Symfony*. Сервер приложений *RoadRunner* позволяет интегрировать среду Go и PHP, управляя запуском
PHP-приложений внутри Go-рутин и балансируя нагрузки между ними; внутри каждого экземпляра приложения PHP 
(worker) запросы обрабатываются в цикле, что предотвращает необходимость инициализации PHP-приложения при 
каждом запросе. Это позволит нам обрабатывать запросы максимально быстро.

Реализован деплой и работа сервиса в кластере *Kubernetes* для максимально гибкого, автоматизированного и масштабируемого
управления работой приложения в продакшне, а также его мониторинга (в рамках тестового задания мониторинг не реализован,
но тот же *Prometeus* интегрируется легко с *RoadRunner* и *Kubernetes*).

Выложил сервис в Kubernetes-облако [DigitalOcean](https://www.digitalocean.com/products/kubernetes/), 
он доступен по адресу: http://alter-test.chuprunov.name

БД развёрнута на managed database сервисе Digital Ocean, который позволяет управлять High-Available кластером БД
с master-slave репликацией и автоматическим failover. Это наиболее приближено к реальным production условиям.

## Деплой в кластер Kubernetes

(Примечание: для Digital Ocean необходимо сначала создать кластер Kubernetes минимум из 2 нод и установить в него 
NGINX Ingress Controller, что делается в интерфейсе самого DO, а также подготовить kubectl для работы с нашим кластером
командой:

`doctl kubernetes cluster kubeconfig save <имя кластера>` 

)

Непосредственно деплой приложения осуществляется так:

`export DATABASE_URL=postgresql://dbuser:dbpasswd@dbhost/alter_test; envsubst <deploy/do-manifest.yaml | kubectl apply -f -; unset DATABASE_URL`

(не прописываем секреты в конфигах. В настоящем продакшне их следует хранить в особом хранилище, например,
*Vault*. Для целей тестового задания подойдёт и передача через переменную окружения).

Деплой выполняется таким образом, чтобы исключить прекращение работы сервиса на момент деплоя. Реплики серверов 
приложения обновляются по одной. Кроме этого, стандартная возможность Kubernetes - откат обновления на предыдущую версию
для всех реплик. 

См. подробнее [deploy](./deploy)

## Запуск локально

Контейнер Docker:

`docker run --env DATABASE_URL=postgres://postgres:postgres@localhost/alter_test?server_version=12 --network="host" unitedt/alter-test-app`

Обязательно указать базу данных (в примере на локальном хосте). Swagger UI и API будут доступны на http://localhost:8080

## Инициализация базы

`bin/console doctrine:database:create`
`bin/console doctrine:schema:create`

Заполнение тестовыми фикстурами:

`bin/console hautelook:fixtures:load`

## Функциональное тестирование

Для функционального тестирования написаны тесты (исполняемые спецификации) на языке *Gherkin*. 

Для запуска тестов:

`vendor/bin/behat`

Тесты расположены [./features](./features)

## Нагрузочное тестирование

Я применил утилиту siege для организации нагрузочного тестирования сервиса. Запустить тестирование можно командой:

`loadtest/run_siege.sh http://alter-test.chuprunov.name`

Скрипт [./loadtest/run_siege.sh](./loadtest/run_siege.sh) настроен на тестирование в 50 потоков, всего 10000 запросов.

Запуск нагрузочного тестирования через Интернет сопряжен с тем, что пропускная способность и временная задержка каналов
связи будет отнимать большую часть времени теста. Например, у меня получается пинг до датацентров Digital Ocean 35-70 мс.
В этих условиях трудно добиться более ~250 requests per second. Что вполне соответствует требованиям теста, однако не 
задействует все возможности используемой конфигурации Kubernetes.

`$ docker run unitedt/alter-test-siege
New configuration template added to /root/.siege
Run siege -C to view the current settings in that file
** SIEGE 4.0.4
** Preparing 50 concurrent users for battle.
The server is now under siege...

Transactions:		       10000 hits
Availability:		      100.00 %
Elapsed time:		       44.37 secs
Data transferred:	        0.77 MB
Response time:		        0.20 secs
Transaction rate:	      225.38 trans/sec
Throughput:		        0.02 MB/sec
Concurrency:		       44.55
Successful transactions:       10000
Failed transactions:	           0
Longest transaction:	        7.35
Shortest transaction:	        0.14
 
IS ASCII: FALSE`


## Ограничения

В рамках тестового задания для экономии времени не было реализовано:

* Негативные тесты - проверка всех условий на нарушение (несуществующий счёт, повторное создание, отрицательный баланс,
перевод суммы, превышающей баланс) и корректную генерацию исключений, не допускающих нарушения. Добавить соотв. тесты 
можно в те же features на Gherkin.

* Имеет определенный смысл (особенно при росте проекта) наряду с функциональными тестами добавить и unit-тесты.

* Для упрощения и сокращения времени сейчас лбработка части условий реализована только в виде constraint базы данных 
(невозможность отрицательного остатка на счету), без конвертации ошибки нарушения условия в логическую ошибку 
приложения. В реальном проекте желательно реализовывать продуманную систему (дерево) исключений.

* Более подробно описать примеры операций и данные в Swagger, желательно в новом формате OpenAPI.

* Доделать контейнер нагрузочного тестирования для запуска в ДЦ облачного провайдера, для тестирования без оверхеда 
Интернет-соединения.

* Нагрузочное тестирование для простоты проводилось на самый потенциально "тяжелый" эндпойнт API - account/transfer. 
Возможно, имеет смысл тестировать нагрузку на все эндпойнты, или симулируя реальные кейсы обращений к API - вводя 
взвешенные коэффициенты обращений к каждому эндпойнту.


## Повышение производительности сервиса

В данной конфигурации вполне возможно достигнуть не менее 1000 RPS используя текущую конфигурацию кластера Kubernetes,
возможно с более мощными нодами. Есть многократный запас роста, который решается добавлением новых реплик application 
серверов, что решается простым изменением конфига Kubernetes и добавлением серверов через интерфейс Digital Ocean (если 
не применять к тому же auto-scaling). В определенный момент это упрётся в производительность БД. На уровне 
Managed PostgreSQL частично разгрузить master DB server можно read-only slave репликой, переправив на неё запросы 
чтения. Далее можно двигаться в сторону партицирования (шардинга) по группам из мастер-серверов и реплик.